{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: http://scikit-learn.org/stable/auto_examples/applications/plot_stock_market.html#sphx-glr-auto-examples-applications-plot-stock-market-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching quote history for 'AAPL'\n",
      "Fetching quote history for 'AIG'\n",
      "Fetching quote history for 'AMZN'\n",
      "Fetching quote history for 'AXP'\n",
      "Fetching quote history for 'BA'\n",
      "Fetching quote history for 'BAC'\n",
      "Fetching quote history for 'CAJ'\n",
      "Fetching quote history for 'CAT'\n",
      "Fetching quote history for 'CL'\n",
      "Fetching quote history for 'CMCSA'\n",
      "Fetching quote history for 'COP'\n",
      "Fetching quote history for 'CSCO'\n",
      "Fetching quote history for 'CVC'\n",
      "Fetching quote history for 'CVS'\n",
      "Fetching quote history for 'CVX'\n",
      "Fetching quote history for 'DD'\n",
      "Fetching quote history for 'DELL'\n",
      "Fetching quote history for 'F'\n",
      "Fetching quote history for 'GD'\n",
      "Fetching quote history for 'GE'\n",
      "Fetching quote history for 'GS'\n",
      "Fetching quote history for 'GSK'\n",
      "Fetching quote history for 'HD'\n",
      "Fetching quote history for 'HMC'\n",
      "Fetching quote history for 'HPQ'\n",
      "Fetching quote history for 'IBM'\n",
      "Fetching quote history for 'JPM'\n",
      "Fetching quote history for 'K'\n",
      "Fetching quote history for 'KMB'\n",
      "Fetching quote history for 'KO'\n",
      "Fetching quote history for 'MAR'\n",
      "Fetching quote history for 'MCD'\n",
      "Fetching quote history for 'MMM'\n",
      "Fetching quote history for 'MSFT'\n",
      "Fetching quote history for 'NAV'\n",
      "Fetching quote history for 'NOC'\n",
      "Fetching quote history for 'NVS'\n",
      "Fetching quote history for 'PEP'\n",
      "Fetching quote history for 'PFE'\n",
      "Fetching quote history for 'PG'\n",
      "Fetching quote history for 'R'\n",
      "Fetching quote history for 'RTN'\n",
      "Fetching quote history for 'SAP'\n",
      "Fetching quote history for 'SNE'\n",
      "Fetching quote history for 'SNY'\n",
      "Fetching quote history for 'TM'\n",
      "Fetching quote history for 'TOT'\n",
      "Fetching quote history for 'TWX'\n",
      "Fetching quote history for 'TXN'\n",
      "Fetching quote history for 'UN'\n",
      "Fetching quote history for 'VLO'\n",
      "Fetching quote history for 'WFC'\n",
      "Fetching quote history for 'WMT'\n",
      "Fetching quote history for 'XOM'\n",
      "Fetching quote history for 'XRX'\n",
      "Fetching quote history for 'YHOO'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: Apple, Amazon, Yahoo\n",
      "Cluster 2: Comcast, Cablevision, Time Warner\n",
      "Cluster 3: ConocoPhillips, Chevron, Total, Valero Energy, Exxon\n",
      "Cluster 4: Cisco, Dell, HP, IBM, Microsoft, SAP, Texas Instruments\n",
      "Cluster 5: Boeing, General Dynamics, Northrop Grumman, Raytheon\n",
      "Cluster 6: AIG, American express, Bank of America, Caterpillar, CVS, DuPont de Nemours, Ford, General Electrics, Goldman Sachs, Home Depot, JPMorgan Chase, Marriott, 3M, Ryder, Wells Fargo, Wal-Mart\n",
      "Cluster 7: McDonald's\n",
      "Cluster 8: GlaxoSmithKline, Novartis, Pfizer, Sanofi-Aventis, Unilever\n",
      "Cluster 9: Kellogg, Coca Cola, Pepsi\n",
      "Cluster 10: Colgate-Palmolive, Kimberly-Clark, Procter Gamble\n",
      "Cluster 11: Canon, Honda, Navistar, Sony, Toyota, Xerox\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110daf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# Author: Gael Varoquaux gael.varoquaux@normalesup.org\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import cluster, covariance, manifold\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Retrieve the data from Internet\n",
    "\n",
    "# The data is from 2003 - 2008. This is reasonably calm: (not too long ago so\n",
    "# that we get high-tech firms, and before the 2008 crash). This kind of\n",
    "# historical data can be obtained for from APIs like the quandl.com and\n",
    "# alphavantage.co ones.\n",
    "start_date = datetime(2003, 1, 1).date()\n",
    "end_date = datetime(2008, 1, 1).date()\n",
    "\n",
    "symbol_dict = {\n",
    "    'TOT': 'Total',\n",
    "    'XOM': 'Exxon',\n",
    "    'CVX': 'Chevron',\n",
    "    'COP': 'ConocoPhillips',\n",
    "    'VLO': 'Valero Energy',\n",
    "    'MSFT': 'Microsoft',\n",
    "    'IBM': 'IBM',\n",
    "    'TWX': 'Time Warner',\n",
    "    'CMCSA': 'Comcast',\n",
    "    'CVC': 'Cablevision',\n",
    "    'YHOO': 'Yahoo',\n",
    "    'DELL': 'Dell',\n",
    "    'HPQ': 'HP',\n",
    "    'AMZN': 'Amazon',\n",
    "    'TM': 'Toyota',\n",
    "    'CAJ': 'Canon',\n",
    "    'SNE': 'Sony',\n",
    "    'F': 'Ford',\n",
    "    'HMC': 'Honda',\n",
    "    'NAV': 'Navistar',\n",
    "    'NOC': 'Northrop Grumman',\n",
    "    'BA': 'Boeing',\n",
    "    'KO': 'Coca Cola',\n",
    "    'MMM': '3M',\n",
    "    'MCD': 'McDonald\\'s',\n",
    "    'PEP': 'Pepsi',\n",
    "    'K': 'Kellogg',\n",
    "    'UN': 'Unilever',\n",
    "    'MAR': 'Marriott',\n",
    "    'PG': 'Procter Gamble',\n",
    "    'CL': 'Colgate-Palmolive',\n",
    "    'GE': 'General Electrics',\n",
    "    'WFC': 'Wells Fargo',\n",
    "    'JPM': 'JPMorgan Chase',\n",
    "    'AIG': 'AIG',\n",
    "    'AXP': 'American express',\n",
    "    'BAC': 'Bank of America',\n",
    "    'GS': 'Goldman Sachs',\n",
    "    'AAPL': 'Apple',\n",
    "    'SAP': 'SAP',\n",
    "    'CSCO': 'Cisco',\n",
    "    'TXN': 'Texas Instruments',\n",
    "    'XRX': 'Xerox',\n",
    "    'WMT': 'Wal-Mart',\n",
    "    'HD': 'Home Depot',\n",
    "    'GSK': 'GlaxoSmithKline',\n",
    "    'PFE': 'Pfizer',\n",
    "    'SNY': 'Sanofi-Aventis',\n",
    "    'NVS': 'Novartis',\n",
    "    'KMB': 'Kimberly-Clark',\n",
    "    'R': 'Ryder',\n",
    "    'GD': 'General Dynamics',\n",
    "    'RTN': 'Raytheon',\n",
    "    'CVS': 'CVS',\n",
    "    'CAT': 'Caterpillar',\n",
    "    'DD': 'DuPont de Nemours'}\n",
    "\n",
    "\n",
    "symbols, names = np.array(sorted(symbol_dict.items())).T\n",
    "\n",
    "quotes = []\n",
    "\n",
    "for symbol in symbols:\n",
    "    print('Fetching quote history for %r' % symbol, file=sys.stderr)\n",
    "    url = ('https://raw.githubusercontent.com/scikit-learn/examples-data/'\n",
    "           'master/financial-data/{}.csv')\n",
    "    quotes.append(pd.read_csv(url.format(symbol)))\n",
    "\n",
    "close_prices = np.vstack([q['close'] for q in quotes])\n",
    "open_prices = np.vstack([q['open'] for q in quotes])\n",
    "\n",
    "# The daily variations of the quotes are what carry most information\n",
    "variation = close_prices - open_prices\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Learn a graphical structure from the correlations\n",
    "edge_model = covariance.GraphicalLassoCV(cv=5)\n",
    "\n",
    "# standardize the time series: using correlations rather than covariance\n",
    "# is more efficient for structure recovery\n",
    "X = variation.copy().T\n",
    "X /= X.std(axis=0)\n",
    "edge_model.fit(X)\n",
    "\n",
    "# #############################################################################\n",
    "# Cluster using affinity propagation\n",
    "\n",
    "_, labels = cluster.affinity_propagation(edge_model.covariance_)\n",
    "n_labels = labels.max()\n",
    "\n",
    "for i in range(n_labels + 1):\n",
    "    print('Cluster %i: %s' % ((i + 1), ', '.join(names[labels == i])))\n",
    "\n",
    "# #############################################################################\n",
    "# Find a low-dimension embedding for visualization: find the best position of\n",
    "# the nodes (the stocks) on a 2D plane\n",
    "\n",
    "# We use a dense eigen_solver to achieve reproducibility (arpack is\n",
    "# initiated with random vectors that we don't control). In addition, we\n",
    "# use a large number of neighbors to capture the large-scale structure.\n",
    "node_position_model = manifold.LocallyLinearEmbedding(\n",
    "    n_components=2, eigen_solver='dense', n_neighbors=6)\n",
    "\n",
    "embedding = node_position_model.fit_transform(X.T).T\n",
    "\n",
    "# #############################################################################\n",
    "# Visualization\n",
    "plt.figure(1, facecolor='w', figsize=(10, 8))\n",
    "plt.clf()\n",
    "ax = plt.axes([0., 0., 1., 1.])\n",
    "plt.axis('off')\n",
    "\n",
    "# Display a graph of the partial correlations\n",
    "partial_correlations = edge_model.precision_.copy()\n",
    "d = 1 / np.sqrt(np.diag(partial_correlations))\n",
    "partial_correlations *= d\n",
    "partial_correlations *= d[:, np.newaxis]\n",
    "non_zero = (np.abs(np.triu(partial_correlations, k=1)) > 0.02)\n",
    "\n",
    "# Plot the nodes using the coordinates of our embedding\n",
    "plt.scatter(embedding[0], embedding[1], s=100 * d ** 2, c=labels,\n",
    "            cmap=plt.cm.nipy_spectral)\n",
    "\n",
    "# Plot the edges\n",
    "start_idx, end_idx = np.where(non_zero)\n",
    "# a sequence of (*line0*, *line1*, *line2*), where::\n",
    "#            linen = (x0, y0), (x1, y1), ... (xm, ym)\n",
    "segments = [[embedding[:, start], embedding[:, stop]]\n",
    "            for start, stop in zip(start_idx, end_idx)]\n",
    "values = np.abs(partial_correlations[non_zero])\n",
    "lc = LineCollection(segments,\n",
    "                    zorder=0, cmap=plt.cm.hot_r,\n",
    "                    norm=plt.Normalize(0, .7 * values.max()))\n",
    "lc.set_array(values)\n",
    "lc.set_linewidths(15 * values)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "# Add a label to each node. The challenge here is that we want to\n",
    "# position the labels to avoid overlap with other labels\n",
    "for index, (name, label, (x, y)) in enumerate(\n",
    "        zip(names, labels, embedding.T)):\n",
    "\n",
    "    dx = x - embedding[0]\n",
    "    dx[index] = 1\n",
    "    dy = y - embedding[1]\n",
    "    dy[index] = 1\n",
    "    this_dx = dx[np.argmin(np.abs(dy))]\n",
    "    this_dy = dy[np.argmin(np.abs(dx))]\n",
    "    if this_dx > 0:\n",
    "        horizontalalignment = 'left'\n",
    "        x = x + .002\n",
    "    else:\n",
    "        horizontalalignment = 'right'\n",
    "        x = x - .002\n",
    "    if this_dy > 0:\n",
    "        verticalalignment = 'bottom'\n",
    "        y = y + .002\n",
    "    else:\n",
    "        verticalalignment = 'top'\n",
    "        y = y - .002\n",
    "    plt.text(x, y, name, size=10,\n",
    "             horizontalalignment=horizontalalignment,\n",
    "             verticalalignment=verticalalignment,\n",
    "             bbox=dict(facecolor='w',\n",
    "                       edgecolor=plt.cm.nipy_spectral(label / float(n_labels)),\n",
    "                       alpha=.6))\n",
    "\n",
    "plt.xlim(embedding[0].min() - .15 * embedding[0].ptp(),\n",
    "         embedding[0].max() + .10 * embedding[0].ptp(),)\n",
    "plt.ylim(embedding[1].min() - .03 * embedding[1].ptp(),\n",
    "         embedding[1].max() + .03 * embedding[1].ptp())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching quote history for 'EALT4.SA'\n"
     ]
    },
    {
     "ename": "RemoteDataError",
     "evalue": "Unable to read URL: https://query1.finance.yahoo.com/v7/finance/download/EALT4.SA?period1=1515549600&events=history&period2=1516067999&interval=1d&crumb=1TQyOkDng8b",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteDataError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a75fcc099c36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2018\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2018\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yahoo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[0mquotes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python35-32\\lib\\site-packages\\pandas_datareader\\data.py\u001b[0m in \u001b[0;36mDataReader\u001b[1;34m(name, data_source, start, end, retry_count, pause, session, access_key)\u001b[0m\n\u001b[0;32m    119\u001b[0m                                 \u001b[0madjust_price\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                                 \u001b[0mretry_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                                 session=session).read()\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdata_source\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"yahoo-actions\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python35-32\\lib\\site-packages\\pandas_datareader\\yahoo\\daily.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;34m\"\"\" read one data from specified URL \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYahooDailyReader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mret_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ret_Index'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_calc_return_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Adj Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python35-32\\lib\\site-packages\\pandas_datareader\\base.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             df = self._read_one_data(self.url,\n\u001b[1;32m--> 181\u001b[1;33m                                      params=self._get_params(self.symbols))\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;31m# Or multiple symbols, (e.g., ['GOOG', 'AAPL', 'MSFT'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python35-32\\lib\\site-packages\\pandas_datareader\\base.py\u001b[0m in \u001b[0;36m_read_one_data\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;34m\"\"\" read one data from specified URL \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'string'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_url_as_StringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'json'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python35-32\\lib\\site-packages\\pandas_datareader\\base.py\u001b[0m in \u001b[0;36m_read_url_as_StringIO\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mOpen\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mand\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \"\"\"\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python35-32\\lib\\site-packages\\pandas_datareader\\base.py\u001b[0m in \u001b[0;36m_get_response\u001b[1;34m(self, url, params, headers)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"?\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murlencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRemoteDataError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unable to read URL: {0}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_crumb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRemoteDataError\u001b[0m: Unable to read URL: https://query1.finance.yahoo.com/v7/finance/download/EALT4.SA?period1=1515549600&events=history&period2=1516067999&interval=1d&crumb=1TQyOkDng8b"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# Author: Gael Varoquaux gael.varoquaux@normalesup.org\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import cluster, covariance, manifold\n",
    "\n",
    "# meus imports\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import requests_cache\n",
    "\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Retrieve the data from Internet\n",
    "\n",
    "# The data is from 2003 - 2008. This is reasonably calm: (not too long ago so\n",
    "# that we get high-tech firms, and before the 2008 crash). This kind of\n",
    "# historical data can be obtained for from APIs like the quandl.com and\n",
    "# alphavantage.co ones.\n",
    "\n",
    "symbol_dict = {\n",
    "    'PETR4.SA': 'Petrobrás',\n",
    "    'EALT4.SA': 'Altona'}\n",
    "\n",
    "\n",
    "symbols, names = np.array(sorted(symbol_dict.items())).T\n",
    "\n",
    "quotes = []\n",
    "\n",
    "for symbol in symbols:\n",
    "    print('Fetching quote history for %r' % symbol, file=sys.stderr)\n",
    "    \n",
    "    expire_after = datetime.timedelta(days=3)\n",
    "    session = requests_cache.CachedSession(cache_name='cache', backend='sqlite', expire_after=expire_after)\n",
    "    start = datetime.datetime(2018, 1, 10)\n",
    "    end = datetime.datetime(2018, 1, 15)\n",
    "    hist = web.DataReader(symbol, 'yahoo', start, end, session=session)\n",
    "    quotes.append(hist)  \n",
    "    \n",
    "close_prices = np.vstack([q['Close'] for q in quotes])\n",
    "open_prices = np.vstack([q['Open'] for q in quotes])\n",
    "\n",
    "# The daily variations of the quotes are what carry most information\n",
    "variation = close_prices - open_prices\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Learn a graphical structure from the correlations\n",
    "edge_model = covariance.GraphicalLassoCV(cv=5)\n",
    "\n",
    "# standardize the time series: using correlations rather than covariance\n",
    "# is more efficient for structure recovery\n",
    "X = variation.copy().T\n",
    "X /= X.std(axis=0)\n",
    "edge_model.fit(X)\n",
    "\n",
    "# #############################################################################\n",
    "# Cluster using affinity propagation\n",
    "\n",
    "_, labels = cluster.affinity_propagation(edge_model.covariance_)\n",
    "n_labels = labels.max()\n",
    "\n",
    "for i in range(n_labels + 1):\n",
    "    print('Cluster %i: %s' % ((i + 1), ', '.join(names[labels == i])))\n",
    "\n",
    "# #############################################################################\n",
    "# Find a low-dimension embedding for visualization: find the best position of\n",
    "# the nodes (the stocks) on a 2D plane\n",
    "\n",
    "# We use a dense eigen_solver to achieve reproducibility (arpack is\n",
    "# initiated with random vectors that we don't control). In addition, we\n",
    "# use a large number of neighbors to capture the large-scale structure.\n",
    "node_position_model = manifold.LocallyLinearEmbedding(\n",
    "    n_components=2, eigen_solver='dense', n_neighbors=6)\n",
    "\n",
    "embedding = node_position_model.fit_transform(X.T).T\n",
    "\n",
    "# #############################################################################\n",
    "# Visualization\n",
    "plt.figure(1, facecolor='w', figsize=(10, 8))\n",
    "plt.clf()\n",
    "ax = plt.axes([0., 0., 1., 1.])\n",
    "plt.axis('off')\n",
    "\n",
    "# Display a graph of the partial correlations\n",
    "partial_correlations = edge_model.precision_.copy()\n",
    "d = 1 / np.sqrt(np.diag(partial_correlations))\n",
    "partial_correlations *= d\n",
    "partial_correlations *= d[:, np.newaxis]\n",
    "non_zero = (np.abs(np.triu(partial_correlations, k=1)) > 0.02)\n",
    "\n",
    "# Plot the nodes using the coordinates of our embedding\n",
    "plt.scatter(embedding[0], embedding[1], s=100 * d ** 2, c=labels,\n",
    "            cmap=plt.cm.nipy_spectral)\n",
    "\n",
    "# Plot the edges\n",
    "start_idx, end_idx = np.where(non_zero)\n",
    "# a sequence of (*line0*, *line1*, *line2*), where::\n",
    "#            linen = (x0, y0), (x1, y1), ... (xm, ym)\n",
    "segments = [[embedding[:, start], embedding[:, stop]]\n",
    "            for start, stop in zip(start_idx, end_idx)]\n",
    "values = np.abs(partial_correlations[non_zero])\n",
    "lc = LineCollection(segments,\n",
    "                    zorder=0, cmap=plt.cm.hot_r,\n",
    "                    norm=plt.Normalize(0, .7 * values.max()))\n",
    "lc.set_array(values)\n",
    "lc.set_linewidths(15 * values)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "# Add a label to each node. The challenge here is that we want to\n",
    "# position the labels to avoid overlap with other labels\n",
    "for index, (name, label, (x, y)) in enumerate(\n",
    "        zip(names, labels, embedding.T)):\n",
    "\n",
    "    dx = x - embedding[0]\n",
    "    dx[index] = 1\n",
    "    dy = y - embedding[1]\n",
    "    dy[index] = 1\n",
    "    this_dx = dx[np.argmin(np.abs(dy))]\n",
    "    this_dy = dy[np.argmin(np.abs(dx))]\n",
    "    if this_dx > 0:\n",
    "        horizontalalignment = 'left'\n",
    "        x = x + .002\n",
    "    else:\n",
    "        horizontalalignment = 'right'\n",
    "        x = x - .002\n",
    "    if this_dy > 0:\n",
    "        verticalalignment = 'bottom'\n",
    "        y = y + .002\n",
    "    else:\n",
    "        verticalalignment = 'top'\n",
    "        y = y - .002\n",
    "    plt.text(x, y, name, size=10,\n",
    "             horizontalalignment=horizontalalignment,\n",
    "             verticalalignment=verticalalignment,\n",
    "             bbox=dict(facecolor='w',\n",
    "                       edgecolor=plt.cm.nipy_spectral(label / float(n_labels)),\n",
    "                       alpha=.6))\n",
    "\n",
    "plt.xlim(embedding[0].min() - .15 * embedding[0].ptp(),\n",
    "         embedding[0].max() + .10 * embedding[0].ptp(),)\n",
    "plt.ylim(embedding[1].min() - .03 * embedding[1].ptp(),\n",
    "         embedding[1].max() + .03 * embedding[1].ptp())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.475756</td>\n",
       "      <td>33461800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>16.490000</td>\n",
       "      <td>16.719999</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.625084</td>\n",
       "      <td>55940900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>16.780001</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>16.620001</td>\n",
       "      <td>16.730000</td>\n",
       "      <td>16.654949</td>\n",
       "      <td>37064900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>16.570000</td>\n",
       "      <td>16.830000</td>\n",
       "      <td>16.754501</td>\n",
       "      <td>26958200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>16.740000</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.709999</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.953606</td>\n",
       "      <td>28400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>17.030001</td>\n",
       "      <td>17.160000</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.953606</td>\n",
       "      <td>35070900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>16.920000</td>\n",
       "      <td>17.049999</td>\n",
       "      <td>16.770000</td>\n",
       "      <td>16.799999</td>\n",
       "      <td>16.724634</td>\n",
       "      <td>28547700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-11</th>\n",
       "      <td>16.879999</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>16.840000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>17.172615</td>\n",
       "      <td>37921500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-12</th>\n",
       "      <td>17.040001</td>\n",
       "      <td>17.410000</td>\n",
       "      <td>17.020000</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>17.222391</td>\n",
       "      <td>45912100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-15</th>\n",
       "      <td>17.320000</td>\n",
       "      <td>17.440001</td>\n",
       "      <td>17.150000</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>17.272169</td>\n",
       "      <td>28945400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-16</th>\n",
       "      <td>17.350000</td>\n",
       "      <td>17.840000</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>17.650000</td>\n",
       "      <td>17.570822</td>\n",
       "      <td>58618300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-17</th>\n",
       "      <td>17.920000</td>\n",
       "      <td>18.360001</td>\n",
       "      <td>17.809999</td>\n",
       "      <td>18.360001</td>\n",
       "      <td>18.277637</td>\n",
       "      <td>58488900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18</th>\n",
       "      <td>18.350000</td>\n",
       "      <td>18.530001</td>\n",
       "      <td>17.930000</td>\n",
       "      <td>18.219999</td>\n",
       "      <td>18.138264</td>\n",
       "      <td>48575800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-19</th>\n",
       "      <td>18.309999</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>18.030001</td>\n",
       "      <td>18.260000</td>\n",
       "      <td>18.178085</td>\n",
       "      <td>33470200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-22</th>\n",
       "      <td>18.260000</td>\n",
       "      <td>18.469999</td>\n",
       "      <td>18.090000</td>\n",
       "      <td>18.469999</td>\n",
       "      <td>18.387144</td>\n",
       "      <td>33920000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-23</th>\n",
       "      <td>18.400000</td>\n",
       "      <td>18.459999</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.240000</td>\n",
       "      <td>18.158175</td>\n",
       "      <td>35567700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-24</th>\n",
       "      <td>18.420000</td>\n",
       "      <td>19.629999</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.253241</td>\n",
       "      <td>89768200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-25</th>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.253241</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-26</th>\n",
       "      <td>19.620001</td>\n",
       "      <td>19.980000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.840595</td>\n",
       "      <td>81989500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-29</th>\n",
       "      <td>19.670000</td>\n",
       "      <td>20.049999</td>\n",
       "      <td>19.570000</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>19.760954</td>\n",
       "      <td>55726200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-30</th>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.360001</td>\n",
       "      <td>19.490000</td>\n",
       "      <td>19.402567</td>\n",
       "      <td>46203000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-31</th>\n",
       "      <td>19.740000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.680000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>19.611628</td>\n",
       "      <td>41576600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>19.760000</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>19.760000</td>\n",
       "      <td>20.520000</td>\n",
       "      <td>20.427946</td>\n",
       "      <td>51950200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>20.299999</td>\n",
       "      <td>20.420000</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>19.969999</td>\n",
       "      <td>19.880415</td>\n",
       "      <td>50657800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>19.650000</td>\n",
       "      <td>19.969999</td>\n",
       "      <td>19.040001</td>\n",
       "      <td>19.040001</td>\n",
       "      <td>18.954588</td>\n",
       "      <td>62268600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>18.660000</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>18.620001</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>19.900324</td>\n",
       "      <td>74146500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>19.969999</td>\n",
       "      <td>20.219999</td>\n",
       "      <td>19.360001</td>\n",
       "      <td>19.440001</td>\n",
       "      <td>19.352793</td>\n",
       "      <td>61910300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>19.549999</td>\n",
       "      <td>19.740000</td>\n",
       "      <td>18.799999</td>\n",
       "      <td>19.049999</td>\n",
       "      <td>18.964542</td>\n",
       "      <td>51115100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-09</th>\n",
       "      <td>19.030001</td>\n",
       "      <td>19.389999</td>\n",
       "      <td>18.510000</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>18.685799</td>\n",
       "      <td>68727600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-14</th>\n",
       "      <td>19.010000</td>\n",
       "      <td>19.360001</td>\n",
       "      <td>18.959999</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>19.163643</td>\n",
       "      <td>43402800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-24</th>\n",
       "      <td>18.350000</td>\n",
       "      <td>18.440001</td>\n",
       "      <td>18.049999</td>\n",
       "      <td>18.299999</td>\n",
       "      <td>18.299999</td>\n",
       "      <td>37893000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-27</th>\n",
       "      <td>18.410000</td>\n",
       "      <td>18.760000</td>\n",
       "      <td>18.299999</td>\n",
       "      <td>18.709999</td>\n",
       "      <td>18.709999</td>\n",
       "      <td>35428000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-28</th>\n",
       "      <td>18.760000</td>\n",
       "      <td>18.850000</td>\n",
       "      <td>18.340000</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>38079200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-29</th>\n",
       "      <td>18.500000</td>\n",
       "      <td>19.309999</td>\n",
       "      <td>18.450001</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>71434300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-30</th>\n",
       "      <td>19.150000</td>\n",
       "      <td>19.540001</td>\n",
       "      <td>18.680000</td>\n",
       "      <td>18.799999</td>\n",
       "      <td>18.799999</td>\n",
       "      <td>63981900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>18.950001</td>\n",
       "      <td>19.430000</td>\n",
       "      <td>18.910000</td>\n",
       "      <td>19.260000</td>\n",
       "      <td>19.260000</td>\n",
       "      <td>75767400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-03</th>\n",
       "      <td>18.990000</td>\n",
       "      <td>19.129999</td>\n",
       "      <td>18.760000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25401600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-04</th>\n",
       "      <td>19.129999</td>\n",
       "      <td>19.190001</td>\n",
       "      <td>18.620001</td>\n",
       "      <td>18.650000</td>\n",
       "      <td>18.650000</td>\n",
       "      <td>39759800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-05</th>\n",
       "      <td>18.559999</td>\n",
       "      <td>18.799999</td>\n",
       "      <td>18.230000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>53967300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-06</th>\n",
       "      <td>18.990000</td>\n",
       "      <td>19.020000</td>\n",
       "      <td>18.480000</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>54304300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-10</th>\n",
       "      <td>19.360001</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>19.049999</td>\n",
       "      <td>19.260000</td>\n",
       "      <td>19.260000</td>\n",
       "      <td>58578100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11</th>\n",
       "      <td>18.870001</td>\n",
       "      <td>18.889999</td>\n",
       "      <td>18.430000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>56495200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-12</th>\n",
       "      <td>18.809999</td>\n",
       "      <td>19.219999</td>\n",
       "      <td>18.639999</td>\n",
       "      <td>18.950001</td>\n",
       "      <td>18.950001</td>\n",
       "      <td>59695700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13</th>\n",
       "      <td>19.030001</td>\n",
       "      <td>19.129999</td>\n",
       "      <td>18.620001</td>\n",
       "      <td>18.709999</td>\n",
       "      <td>18.709999</td>\n",
       "      <td>36808700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-14</th>\n",
       "      <td>18.799999</td>\n",
       "      <td>18.959999</td>\n",
       "      <td>18.480000</td>\n",
       "      <td>18.790001</td>\n",
       "      <td>18.790001</td>\n",
       "      <td>55756300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-17</th>\n",
       "      <td>18.629999</td>\n",
       "      <td>19.490000</td>\n",
       "      <td>18.629999</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>71289500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-18</th>\n",
       "      <td>19.500000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>19.469999</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>72959100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19</th>\n",
       "      <td>19.930000</td>\n",
       "      <td>20.459999</td>\n",
       "      <td>19.830000</td>\n",
       "      <td>19.980000</td>\n",
       "      <td>19.980000</td>\n",
       "      <td>60563700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-20</th>\n",
       "      <td>20.260000</td>\n",
       "      <td>20.350000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>19.870001</td>\n",
       "      <td>19.870001</td>\n",
       "      <td>56206900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-21</th>\n",
       "      <td>20.150000</td>\n",
       "      <td>20.299999</td>\n",
       "      <td>19.950001</td>\n",
       "      <td>20.139999</td>\n",
       "      <td>20.139999</td>\n",
       "      <td>58517300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-24</th>\n",
       "      <td>20.200001</td>\n",
       "      <td>20.410000</td>\n",
       "      <td>19.920000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>54332900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-25</th>\n",
       "      <td>19.700001</td>\n",
       "      <td>20.150000</td>\n",
       "      <td>19.530001</td>\n",
       "      <td>20.080000</td>\n",
       "      <td>20.080000</td>\n",
       "      <td>54462300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-26</th>\n",
       "      <td>20.240000</td>\n",
       "      <td>20.299999</td>\n",
       "      <td>19.969999</td>\n",
       "      <td>20.190001</td>\n",
       "      <td>20.190001</td>\n",
       "      <td>60060800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-27</th>\n",
       "      <td>20.500000</td>\n",
       "      <td>21.459999</td>\n",
       "      <td>20.469999</td>\n",
       "      <td>21.459999</td>\n",
       "      <td>21.459999</td>\n",
       "      <td>104177300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-28</th>\n",
       "      <td>21.129999</td>\n",
       "      <td>21.940001</td>\n",
       "      <td>21.020000</td>\n",
       "      <td>21.090000</td>\n",
       "      <td>21.090000</td>\n",
       "      <td>91254600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>21.250000</td>\n",
       "      <td>21.360001</td>\n",
       "      <td>20.799999</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>56540400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-02</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.820000</td>\n",
       "      <td>21.900000</td>\n",
       "      <td>22.820000</td>\n",
       "      <td>22.820000</td>\n",
       "      <td>127231800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-04</th>\n",
       "      <td>23.450001</td>\n",
       "      <td>24.520000</td>\n",
       "      <td>23.209999</td>\n",
       "      <td>24.020000</td>\n",
       "      <td>24.020000</td>\n",
       "      <td>99743300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-05</th>\n",
       "      <td>24.490000</td>\n",
       "      <td>24.590000</td>\n",
       "      <td>23.660000</td>\n",
       "      <td>23.959999</td>\n",
       "      <td>23.959999</td>\n",
       "      <td>104693400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close       Volume\n",
       "Date                                                                          \n",
       "2018-01-02  16.190001  16.549999  16.190001  16.549999  16.475756   33461800.0\n",
       "2018-01-03  16.490000  16.719999  16.370001  16.700001  16.625084   55940900.0\n",
       "2018-01-04  16.780001  16.959999  16.620001  16.730000  16.654949   37064900.0\n",
       "2018-01-05  16.700001  16.860001  16.570000  16.830000  16.754501   26958200.0\n",
       "2018-01-08  16.740000  17.030001  16.709999  17.030001  16.953606   28400000.0\n",
       "2018-01-09  17.030001  17.160000  16.959999  17.030001  16.953606   35070900.0\n",
       "2018-01-10  16.920000  17.049999  16.770000  16.799999  16.724634   28547700.0\n",
       "2018-01-11  16.879999  17.299999  16.840000  17.250000  17.172615   37921500.0\n",
       "2018-01-12  17.040001  17.410000  17.020000  17.299999  17.222391   45912100.0\n",
       "2018-01-15  17.320000  17.440001  17.150000  17.350000  17.272169   28945400.0\n",
       "2018-01-16  17.350000  17.840000  17.299999  17.650000  17.570822   58618300.0\n",
       "2018-01-17  17.920000  18.360001  17.809999  18.360001  18.277637   58488900.0\n",
       "2018-01-18  18.350000  18.530001  17.930000  18.219999  18.138264   48575800.0\n",
       "2018-01-19  18.309999  18.420000  18.030001  18.260000  18.178085   33470200.0\n",
       "2018-01-22  18.260000  18.469999  18.090000  18.469999  18.387144   33920000.0\n",
       "2018-01-23  18.400000  18.459999  18.000000  18.240000  18.158175   35567700.0\n",
       "2018-01-24  18.420000  19.629999  18.420000  19.340000  19.253241   89768200.0\n",
       "2018-01-25  19.340000  19.340000  19.340000  19.340000  19.253241          0.0\n",
       "2018-01-26  19.620001  19.980000  19.100000  19.930000  19.840595   81989500.0\n",
       "2018-01-29  19.670000  20.049999  19.570000  19.850000  19.760954   55726200.0\n",
       "2018-01-30  19.770000  19.770000  19.360001  19.490000  19.402567   46203000.0\n",
       "2018-01-31  19.740000  19.930000  19.680000  19.700001  19.611628   41576600.0\n",
       "2018-02-01  19.760000  20.620001  19.760000  20.520000  20.427946   51950200.0\n",
       "2018-02-02  20.299999  20.420000  19.850000  19.969999  19.880415   50657800.0\n",
       "2018-02-05  19.650000  19.969999  19.040001  19.040001  18.954588   62268600.0\n",
       "2018-02-06  18.660000  19.990000  18.620001  19.990000  19.900324   74146500.0\n",
       "2018-02-07  19.969999  20.219999  19.360001  19.440001  19.352793   61910300.0\n",
       "2018-02-08  19.549999  19.740000  18.799999  19.049999  18.964542   51115100.0\n",
       "2018-02-09  19.030001  19.389999  18.510000  18.770000  18.685799   68727600.0\n",
       "2018-02-14  19.010000  19.360001  18.959999  19.250000  19.163643   43402800.0\n",
       "...               ...        ...        ...        ...        ...          ...\n",
       "2018-08-24  18.350000  18.440001  18.049999  18.299999  18.299999   37893000.0\n",
       "2018-08-27  18.410000  18.760000  18.299999  18.709999  18.709999   35428000.0\n",
       "2018-08-28  18.760000  18.850000  18.340000  18.350000  18.350000   38079200.0\n",
       "2018-08-29  18.500000  19.309999  18.450001  19.299999  19.299999   71434300.0\n",
       "2018-08-30  19.150000  19.540001  18.680000  18.799999  18.799999   63981900.0\n",
       "2018-08-31  18.950001  19.430000  18.910000  19.260000  19.260000   75767400.0\n",
       "2018-09-03  18.990000  19.129999  18.760000  19.000000  19.000000   25401600.0\n",
       "2018-09-04  19.129999  19.190001  18.620001  18.650000  18.650000   39759800.0\n",
       "2018-09-05  18.559999  18.799999  18.230000  18.750000  18.750000   53967300.0\n",
       "2018-09-06  18.990000  19.020000  18.480000  18.990000  18.990000   54304300.0\n",
       "2018-09-10  19.360001  19.600000  19.049999  19.260000  19.260000   58578100.0\n",
       "2018-09-11  18.870001  18.889999  18.430000  18.500000  18.500000   56495200.0\n",
       "2018-09-12  18.809999  19.219999  18.639999  18.950001  18.950001   59695700.0\n",
       "2018-09-13  19.030001  19.129999  18.620001  18.709999  18.709999   36808700.0\n",
       "2018-09-14  18.799999  18.959999  18.480000  18.790001  18.790001   55756300.0\n",
       "2018-09-17  18.629999  19.490000  18.629999  19.400000  19.400000   71289500.0\n",
       "2018-09-18  19.500000  20.250000  19.469999  20.250000  20.250000   72959100.0\n",
       "2018-09-19  19.930000  20.459999  19.830000  19.980000  19.980000   60563700.0\n",
       "2018-09-20  20.260000  20.350000  19.750000  19.870001  19.870001   56206900.0\n",
       "2018-09-21  20.150000  20.299999  19.950001  20.139999  20.139999   58517300.0\n",
       "2018-09-24  20.200001  20.410000  19.920000  20.000000  20.000000   54332900.0\n",
       "2018-09-25  19.700001  20.150000  19.530001  20.080000  20.080000   54462300.0\n",
       "2018-09-26  20.240000  20.299999  19.969999  20.190001  20.190001   60060800.0\n",
       "2018-09-27  20.500000  21.459999  20.469999  21.459999  21.459999  104177300.0\n",
       "2018-09-28  21.129999  21.940001  21.020000  21.090000  21.090000   91254600.0\n",
       "2018-10-01  21.250000  21.360001  20.799999  21.000000  21.000000   56540400.0\n",
       "2018-10-02  22.000000  22.820000  21.900000  22.820000  22.820000  127231800.0\n",
       "2018-10-03        NaN        NaN        NaN        NaN        NaN          NaN\n",
       "2018-10-04  23.450001  24.520000  23.209999  24.020000  24.020000   99743300.0\n",
       "2018-10-05  24.490000  24.590000  23.660000  23.959999  23.959999  104693400.0\n",
       "\n",
       "[192 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'filter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f9ad1fa4f560>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquotes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Open'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'filter'"
     ]
    }
   ],
   "source": [
    "new = quotes.filter(['Date', 'Open', 'Close'], axis=1)\n",
    "new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
